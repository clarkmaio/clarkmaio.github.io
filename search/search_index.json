{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ciau","text":"<p>i am Andrea, you can call me Andrea (or clarkmaio)  i work as data scientist but I am a mathematician</p> <p> </p>"},{"location":"#favorite-books","title":"favorite books","text":"<ul> <li>Guns, Germs and Steel: The Fates of Human Societies, Jered Diamond</li> <li>The Gospel According to Jesus Christ, Jose Saramago</li> <li>Slam Dunk, Takehiko Inoue</li> </ul>"},{"location":"#favorire-boardgames","title":"favorire boardgames","text":"<ul> <li>Power Grid</li> <li>Secret Hitler</li> </ul>"},{"location":"pages/blog/","title":"Blog","text":""},{"location":"pages/blog/#2023","title":"2023","text":""},{"location":"pages/blog/#dunk","title":"Dunk","text":""},{"location":"pages/blog/#2022","title":"2022","text":""},{"location":"pages/blog/#maximum-entropy-priors","title":"Maximum entropy priors","text":""},{"location":"pages/blog/subpages/dunk/","title":"Dunk","text":"<p>So here the thing, in the last period I've started reading Slam Dunk. It is a very nice comic.  Of course I use to watch the cartoon on MTV when I was a boy but now I am really into the books, and I am really fascinated by the whole story and the characters... but I don't want to talk about it.</p> <p>The only thing that matter is that it really motivated me to train in order to do a slam dunk: namely I am going to train to jump high.</p> <p>This will be a dynamic post which means that it will change during time. Infact I will report my improments of my training with few tables and plots.</p> <p>I hope this will help my ego and my self to not stop the training.</p>"},{"location":"pages/blog/subpages/maximum_entropy_priors/","title":"Maximum entropy priors","text":"<p>In this period I am studying a lot about Bayesian statistics. The focus is of course on the applications, in particular using PyMC package on Python.</p> <p>Ofcourse one of the most common question when studying Bayesian statistics is: Which prior I am suppose to use? You want to inject as much info as possible, but usually you have very few information to inject.</p>"},{"location":"pages/hobbies/","title":"Index","text":""},{"location":"pages/hobbies/#photography","title":"photography","text":""},{"location":"pages/hobbies/#dunk","title":"dunk","text":""},{"location":"pages/hobbies/#amigurumi","title":"amigurumi","text":""},{"location":"pages/hobbies/subpages/dunk/","title":"dunk","text":"<p>I want dunk.</p>"},{"location":"pages/hobbies/subpages/dunk/#jump-height","title":"jump height","text":"Date cm 01/01/01 10"},{"location":"pages/hobbies/subpages/dunk/#max-box-squat","title":"max box squat","text":"Date Kg 01/01/01 110"},{"location":"pages/hobbies/subpages/photo/","title":"photography","text":"<p>I use a Canon AE1-Program with 50mm lens.</p> <ul> <li> <p> Kungsladen</p> <p>Photos of my 2 hiking trips in the Kungsladen. </p> <p> Have a look</p> </li> <li> <p> Carneval of Ivrea</p> <p>Pretty unique folcloristic event that take place during carneval in Ivrea (Italy). I've never seen so much violence, happiness and oranges in the same place.</p> <p> Have a look</p> </li> </ul>"},{"location":"pages/hobbies/subpages/photo/photo_ivrea/","title":"Carneval of Ivrea 2024","text":"<p>"},{"location":"pages/hobbies/subpages/photo/photo_kungsladen/","title":"Kungsladen","text":""},{"location":"pages/hobbies/subpages/photo/photo_kungsladen/#abisko-nikkaluotta-2023","title":"Abisko  Nikkaluotta [2023]","text":""},{"location":"pages/hobbies/subpages/photo/photo_kungsladen/#abisko-hemaven-2024","title":"Abisko  Hemaven [2024]","text":""},{"location":"pages/projects/","title":"Index","text":""},{"location":"pages/projects/#essentials","title":"essentials","text":""},{"location":"pages/projects/subpages/essentials/","title":"Essentials","text":"<p>After having worked on very different projects I've realised that still there are objects that I end up implementing every time.</p> <p>I'v decided to implement them once and import them from a \"general\" repository.</p> <p>In this page I will present main tools with few examples.</p> <p>Info</p> <p>You can find this tool box in the github repository clarkpy_essentials.</p> <p>To install the repository: <pre><code>pip install git+https://github.com/clarkmaio/clarkpy_essentials.git\n</code></pre></p>"},{"location":"pages/projects/subpages/essentials/#parsermanager","title":"ParserManager","text":"<p>Let's start from a dummy one: the <code>ParserManager</code>.</p> <p>I just do not like to edit parser from a <code>.py</code> file</p> <p><code>ParserManager</code> is just a class that parse a <code>yaml</code> file and build a parser using the standard library <code>argparser</code>.</p> <p>Parser keys will be stored in a dictionary ready to be queried.</p> <pre><code># Example of parser_conf.yml\nvariable_int:\n  default: 9\n  help: 'This variable is an integer'\n\nvariable_str:\n  default: abc\n  help: 'This variable is a string'\n\nvariable_nargs:\n  default: ['a', 'b', 'c']\n  nargs: '*'\n</code></pre> <pre><code>from clarkpy_essentials import ParserManager\n\nPARSER_CONF = `/path_to_parser/parser_conf.yml`\nparser_args = ParserManager.load(path = PARSER_CONF)\n\n# parser_args is now just a dictionary\nprint('variable_int', parser_args['variable_int'])\nprint('variable_nargs', parser_args['variable_nargs'])\n</code></pre>"},{"location":"pages/projects/subpages/essentials/#datacatalog","title":"DataCatalog","text":"<p>This class is nothing but an huge if/else function to handle different type of dataset.</p> <p>The idea has been stolen directly from kedro than implement a very similar structure. In kedro the user write down a yaml file to map dataset to a label. The dataset can be then loaded in pipeline simply using the label as input.</p> <p>Since I was looking for something more explicit and a tool that could be used outside a kedro pipeline I've implemented the <code>DataCatalog</code> class.</p> <p>It is important to specify for each label the parameters:</p> <ul> <li><code>type</code>: namely the way the dataset will be loaded. Can be <code>pandas.csv</code>, <code>pandas.excel</code>, <code>pandas.hdf</code>, <code>pandas.parquet</code>, <code>polars.csv</code>, <code>polars.parquet</code>,<code>yaml</code>, <code>json</code>, <code>torch</code>, <code>pickle</code></li> <li><code>filepath</code>: the path to the file. By default this is a relative path that will be appended to <code>source_path</code> defined in the constructor. You can refer to an absolute path using the prefix <code>@abs:</code></li> <li><code>load_kwargs</code>: additional paramters that will be passed to loader fucntion as kwargs</li> </ul> <pre><code># Example of a data catalog yml\nPandasDataset:\n    type: pandas.csv\n    filepath: dataset/csv_dataset.csv\n    load_kwargs:\n        sep: ','\n\nPolarsDataset:\n    type: polars.parquet\n    filepath: @abs:/home/user/dataset/parquet_dataset.parquet\n\nUrlPandasDataset:\n    type: pandas.csv\n    filepath: @abs:https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv\n    load_kwargs:\n        sep: ','\n</code></pre> <pre><code>from clarkpy_essentials import DataCatalog\n\n# Initialize the datacatalog specifying the catalog.yml path and the source path that will be used to load datasets.\nSOURCE_PATH = '/home/user'\nCATALOG_PATH = '/home/user/catalog.yml'\ndc = DataCatalog(catalog=CATALOG_PATH, source_path = SOURCE_PATH)\n\nprint('Pandas Dataset', dc('PandasDataset').head(5))\nprint('Polars Dataset', dc('PolarsDataset').head(5))\nprint('URL Pandas Dataset', dc('UrlPandasDataset').head(5))\n</code></pre>"},{"location":"pages/projects/subpages/essentials/#context","title":"Context","text":"<p>This is a very trivial class. The only purpose it to store global senttings and variables as properties of a class.</p> <p>Whatever you pass to the constructor of this class will be trasformed in a property.</p> <p>Note</p> <p><code>catalog</code> is a privileged key that is ment to store a <code>DataCatalog</code> instance. It is privileged in the sense that whatever is stored in this key will be treated as <code>DataCatalog</code> intance in <code>Pipeline</code> (see below).</p> <pre><code>from clarkpy_essentials import Context\n\nglobal_vars = {'GLOBAL': 100}\ncontext = Context(parser=parser_args, global_vars=global_vars, catalog=dc)\n\nprint(context.parser)\nprint(context.global_vars)\nprint(context.catalog)\n</code></pre>"},{"location":"pages/projects/subpages/essentials/#pipelines-and-nodes","title":"Pipelines and nodes","text":"<p>Again I've tried to copy a feature of kedro package but tring to make it easier to use it.</p> <p>I really like the way Pipelines and Nodes work in kedro, in particular the elegant way to pass input/output across different nodes.</p> <p>You can use mine <code>Pipeline</code> and <code>Node</code> classes to accomplish the same but you can easily use them in your program without using kedro structure.</p> <p>Here a dummy example:</p> <pre><code>from clarkpy_essentials import Pipeline, Node, Context\n\n# ------------ Node fucntions --------------\ndef prod(x: float, y: float) -&gt; float:\n  return x*y\n\n\ndef sum(x: float, y: float) -&gt; float:\n  reutrn x+y\n\n\n# ------------ Create Context --------------\nGLOBAL_VARIABLES = {'var1': 1, 'var2': 100, 'var3': 10}\ncontext = Context(global_variables=GLOBAL_VARIABLES)\n\n# ------------ Initialize Pipeline ---------\npipeline = Pipeline([\n    Node(func=prod,\n         inputs=['context.global_variables.var1', 'context.global_variables.var2'],\n         outputs='output_prod'),\n    Node(func=sum,\n         inputs=['output_prod', 'context.global_variables.var3'],\n         outputs='outpout_sum')\n])\n\n# ------------ Run Pipeline ----------------\npipeline_results = pipeline.run(context=context)\nprint('All pipeline variables', pipeline_results)\n</code></pre> <p>For more complex example have a look at mine <code>forecast</code> template.</p>"},{"location":"pages/projects/subpages/essentials/#datatransformer","title":"DataTransformer","text":"<p>When dealing with multiple models it happens that different data processing are needed depending on the model you are using.</p> <p>To make it easyier to control this operations I've created a class that take in input a list of instructions and transform a dataset accordingly.</p> <p>Ideally you should create instructions (in the form of a <code>yaml</code>) for each model.</p> <p>To use correctly this class you should:</p> <ol> <li> <p>Write the functions to transform data using the template:</p> <pre><code>def transformer_1(X, **kwars):\n    transform X some how\n    return X\n\ndef transformer_2(X, **kwars):\n    transform X some how\n    return X\n</code></pre> </li> <li> <p>Create an instance of <code>DataTransformer</code> and map the functions associating a label</p> <pre><code>dt = DataTransformer({\n    't1': trabsformer_1,\n    't2': transformer_2 \n})\n</code></pre> </li> <li> <p>Create list of instructions.</p> <p>Each instruction step must consist in a dictionary containing the keys:</p> <ul> <li><code>type</code>: label of the function to apply </li> <li><code>kargs</code> [optional]: function kwargs</li> </ul> <pre><code>instructions = [\n    {\n        'type': 't1'\n        'kargs': {\n            'kwarg1': ...,\n            'kwarg2': ...\n        }\n    },\n\n    'type': 't2'\n        'kargs': {\n            'kwarg1': ...,\n            'kwarg2': ...\n        }\n]\n</code></pre> </li> <li> <p>Transform data <pre><code>X_transformed = dt.transform(X, instructions=instructions)\n</code></pre></p> </li> </ol> <p>Here a complete dummy example:</p> <pre><code>def f1(X):\n    return X\n\ndef f2(X, alpha):\n    return X*alpha\n\ndt = DataTransformer()\ndt.add_transformer_catalog({\n    'identity': f1,\n    'mul': f2\n})\n\n\ninstructions = [\n    {\n        'type': 'identity'\n    },\n\n    {\n        'type': 'mul',\n        'kwargs': {\n            'alpha': 2\n        }\n    }\n]\n\n\nX = [1,2,3,4,5]\nX_transformed = dt.transform(X=X, instructions=instructions)\nprint(X_transformed)\n</code></pre>"},{"location":"pages/projects/subpages/essentials/#decorators","title":"Decorators","text":"<ul> <li><code>@force_kwargs</code>:  raise an error if function arguments are not passed through key.</li> <li><code>@deepcopy_args</code>: deep copy args and kwargs passed to a function.</li> </ul>"},{"location":"pages/til/","title":"Today I learned","text":"<p>01.01.2023 This is a test</p>"},{"location":"pages/til/subpages/test/","title":"Sa sa prova","text":"<p>Today I learned how to create a TIL post and create a link from TIL page to the post it self. It was not that hard.</p> <p>For sure I have to work on the design.</p>"},{"location":"pages/useful%21/","title":"Index","text":""},{"location":"pages/useful%21/#people","title":"People","text":"<ul> <li>koaning the idea of this website and the website itself have been copied from this man</li> <li>m-clark GAM God</li> <li>ritchie vink</li> <li>robj hyndman</li> <li>daniel linssen amazing game developer</li> <li>pesciolini patatini veeeeeeeeery nice paints</li> </ul>"},{"location":"pages/useful%21/#links","title":"Links","text":"<ul> <li>matplotlib tricks</li> </ul>"}]}